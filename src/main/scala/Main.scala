import java.io.{ObjectOutputStream, FileOutputStream, Serializable}

import org.apache.spark.SparkConf
import org.apache.spark.rdd.RDD
import org.apache.spark.storage.StorageLevel
import org.apache.spark.streaming.{Seconds, StreamingContext}
import org.apache.spark.streaming.StreamingContext._
import rx.lang.scala.Observable
import scala.concurrent.duration._

object Main {
  val clock = Observable.interval(100 milliseconds)

  def main(args: Array[String]): Unit = {
    /*
    val conf = new SparkConf().setMaster("local[2]").setAppName("Clock")
    val ssc = new StreamingContext(conf, Seconds(1))

    val clock = Observable.just(1L) //Observable.interval(100 milliseconds)
    val stream = RxUtils.createStream(ssc, clock)

    stream.foreachRDD(rdd => {
      val top = rdd.take(10)

      top.foreach(x => {
        println("Item: " + x)
      })

      println("Count: " + rdd.count())
    })

    ssc.start()
    ssc.awaitTermination()
    */

    // Create the context with a 1 second batch size. The "local[3]" means 3 threads.
    val sparkConf = new SparkConf().setMaster("local[4]").setAppName("NetworkWordCount")
    val ssc = new StreamingContext(sparkConf, Seconds(1))

    // Broadcast
    val oe = Observable.empty

    // Create a socket stream on target ip:port and count the
    // words in input stream of \n delimited text (eg. generated by 'nc')
    // Note that no duplication in storage level only for running locally.
    // Replication necessary in distributed scenario for fault tolerance.
    val lines = ssc.socketTextStream("localhost", 9999, StorageLevel.MEMORY_AND_DISK_SER)
    val words = lines.flatMap(_.split(" "))
    val wordCounts = words.map(x => (x, 1)).reduceByKey(_ + _)

    wordCounts.foreachRDD(rdd =>
      println(rdd.collect().mkString(" "))
    )

    // This seems to work! Apparently, collect() sends the RDD back or someth.?
    val o = Observable[Int](subscriber => {
      wordCounts.foreachRDD((x: RDD[(String, Int)]) => {
        for (y <- x.collect()) {
          subscriber.onNext(y._2)
        }
      })
    })

    o.subscribe(l =>
      println("Observable says: " + l)
    )

    /*
    val o = Observable[(String, Int)](subscriber => {
      wordCounts.foreachRDD((x: RDD[(String, Int)]) =>
        x.foreach((y: (String, Int)) => {
          println(y)
          println(Thread.currentThread().getName)
          subscriber.onNext(y) // Spark serializes this closure, but subscriber is not serializable, grr..
        })
      )

      subscriber.onCompleted()
    })
    */

    // Print what our observable emits
    //oe.subscribe(x => println(x))

    //wordCounts.print()

    ssc.start()
    ssc.awaitTermination()
  }
}
